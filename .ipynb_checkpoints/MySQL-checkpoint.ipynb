{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as read_file:\n",
    "    client = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000001920ADC0518>\n"
     ]
    }
   ],
   "source": [
    "db = mysql.connect(\n",
    "    host = 'localhost',\n",
    "    buffered = True,\n",
    "    user = client['MySQL User'],\n",
    "    passwd = client['MySQL Pass'],\n",
    "    database = 'scopus'\n",
    ")\n",
    "\n",
    "# column names\n",
    "source_col = [\n",
    "    'source_id', 'title', 'url', 'issn', 'isbn', 'subject', 'publisher', 'type'\n",
    "]\n",
    "paper_col = [\n",
    "    'paper_id', 'eid', 'title', 'type', 'type_description', 'abstract', \n",
    "    'total_author', 'open_access', 'cited_cnt', 'url', 'article_no', \n",
    "    'fund_no', 'retrieval_time',  'create_time',  'source_id',  'doi', \n",
    "    'volume',  'issue',  'date',  'page_range'\n",
    "]\n",
    "paper_author_col = ['paper_id', 'author_id', 'author_no']\n",
    "author_col = [\n",
    "    'author_id', 'first', 'last', 'initials', 'url', 'sex', 'type', 'rank', 'email',\n",
    "]\n",
    "author_department_col = ['author_id', 'department_id']\n",
    "department_col = [\n",
    "    'department_id', 'name', 'abbreviation', 'type', 'lat', 'lng'\n",
    "]\n",
    "department_institution_col = ['department_id', 'institution_id']\n",
    "institution_col = [\n",
    "    'institution_id', 'name', 'abbreviation', 'city', 'country', 'url', 'type', 'lat', 'lng'\n",
    "]\n",
    "\n",
    "print(db)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('author_id', 'int(11)', 'NO', 'PRI', None, '')\n",
      "('first', 'varchar(45)', 'YES', '', None, '')\n",
      "('last', 'varchar(45)', 'YES', '', None, '')\n",
      "('initials', 'varchar(45)', 'YES', '', None, '')\n",
      "('url', 'varchar(256)', 'YES', '', None, '')\n",
      "('sex', 'tinyint(1)', 'YES', '', None, '')\n",
      "('type', 'varchar(45)', 'YES', '', None, '')\n",
      "('rank', 'varchar(45)', 'YES', '', None, '')\n",
      "('email', 'varchar(128)', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('DESCRIBE author')\n",
    "databases = cursor.fetchall()\n",
    "for database in databases:\n",
    "    print(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_q = '''\n",
    "    INSERT INTO scopus.source (\n",
    "        source_id, title, url, issn, isbn, subject, publisher, type\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "paper_q = '''\n",
    "    INSERT INTO paper (\n",
    "        paper_id, eid, title, type, type_description, abstract, \n",
    "        total_author, open_access, cited_cnt, url, article_no, \n",
    "        fund_no, retrieval_time,  create_time, source_id, doi, \n",
    "        volume,  issue,  date,  page_range\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \n",
    "        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "author_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        author_id, first, last, initials, url, sex, type, rank, email\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "paper_author_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        paper_id, author_id, author_no\n",
    "    ) VALUES (\n",
    "        %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "department_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        department_id, name, abbreviation, type, lat, lng\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "author_department_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        author_id, department_id\n",
    "    ) VALUES (\n",
    "        %s, %s\n",
    "    )\n",
    "'''\n",
    "institution_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        institution_id, name, abbreviation, city, country, url, type, lat, lng\n",
    "    ) VALUES (\n",
    "        %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "    )\n",
    "'''\n",
    "department_institution_q = '''\n",
    "    INSERT INTO paper_author (\n",
    "        department_id, institution_id\n",
    "    ) VALUES (\n",
    "        %s, %s\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = (1358,'Chem Proceedings','https://www.google.com',12345678,123,'ChE','Sharif','Journal')\n",
    "cursor.execute(source_q, values)\n",
    "db.commit()\n",
    "\n",
    "print(cursor.rowcount, \"record inserted\")\n",
    "db.close()\n",
    "# cursor.execute(paper_q, (123,4345,'awef','ar','','',1,1,1,'wef','','','2001-12-12 12:13:24','2038-01-19 03:14:07',1356,'','','','2008-05-06',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "\n",
    "with io.open(os.path.join(path, files[0]), 'r', encoding='utf8') as raw:\n",
    "    data = json.load(raw)\n",
    "\n",
    "faculties = []\n",
    "with io.open('data\\\\faculties.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        if row['Scopus']:\n",
    "            row['Scopus'] = list(map(int, row['Scopus'].split(',')))\n",
    "        faculties.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84855594214\n",
      "84855584394\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "1062 (23000): Duplicate entry '28075' for key 'PRIMARY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    394\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                                raw_as_string=raw_as_string)\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Duplicate entry '28075' for key 'PRIMARY'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-b2f288e5e31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prism:aggregationType'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'prism:aggregationType'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         ]\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         paper_info = [\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\mysql\\connector\\cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    264\u001b[0m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[1;32m    265\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                                          raw_as_string=self._raw_as_string)\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             raise errors.get_mysql_exception(msg=exc.msg, errno=exc.errno,\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n\u001b[0;32m--> 398\u001b[0;31m                                              sqlstate=exc.sqlstate)\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unix_socket\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: 1062 (23000): Duplicate entry '28075' for key 'PRIMARY'"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "#     print(file)\n",
    "    year = file.split('.')[0].split('_')[-4][1:]\n",
    "    with io.open(os.path.join(path, file), 'r', encoding='utf8') as raw:\n",
    "        data = json.load(raw)\n",
    "    data = data['search-results']['entry']\n",
    "    for paper in data:\n",
    "        print(int(paper['dc:identifier'].split(':')[1]))\n",
    "        rnd_source = random.randint(100000,200000)\n",
    "        source_info = [\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:publicationName'] if 'prism:publicationName' in paper.keys() else 'No Name!'),\n",
    "            'https://www.scopus.com/sourceid/', # url\n",
    "            (paper['prism:issn'] if 'prism:issn' in paper.keys() else None),\n",
    "            (paper['prism:isbn'][0]['$'] if 'prism:isbn' in paper.keys() else None),\n",
    "            None, # **subject\n",
    "            None, # **publisher\n",
    "            (paper['prism:aggregationType'] if 'prism:aggregationType' in paper.keys() else None),\n",
    "        ]\n",
    "        cursor.execute(source_q, source_info)\n",
    "        \n",
    "        paper_info = [\n",
    "            int(paper['dc:identifier'].split(':')[1]),\n",
    "            paper['eid'],\n",
    "            paper['dc:title'],\n",
    "            (paper['subtype'] if 'subtype' in paper.keys() else None),\n",
    "            (paper['subtypeDescription'] if 'subtypeDescription' in paper.keys() else None),\n",
    "            (paper['dc:description'] if 'dc:description' in paper.keys() else None),\n",
    "            paper['author-count']['$'],\n",
    "            (paper['openaccess'] if 'openaccess' in paper.keys() else None),\n",
    "            paper['citedby-count'],\n",
    "            paper['link'][-2]['@href'],\n",
    "            (paper['article-number'] if 'article-number' in paper.keys() else None),\n",
    "            (paper['fund-no'] if 'fund-no' in paper.keys() else None),\n",
    "            datetime.utcfromtimestamp(int(file.split('.')[0].split('_')[-1])).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:doi'] if 'prism:doi' in paper.keys() else None),\n",
    "            (paper['prism:volume'] if 'prism:volume' in paper.keys() else None),\n",
    "            (paper['prism:issueIdentifier'] if 'prism:issueIdentifier' in paper.keys() else None),\n",
    "            (datetime.strptime(paper['prism:coverDate'], '%Y-%m-%d').strftime('%Y-%m-%d') if 'prism:coverDate' in paper.keys() else year),\n",
    "            (paper['prism:pageRange'] if 'prism:pageRange' in paper.keys() else None),\n",
    "        ]\n",
    "#         cursor.execute(paper_q, paper_info)\n",
    "        \n",
    "        author_info = []\n",
    "        paper_author_info = []\n",
    "        for auth in paper['author']:\n",
    "            author_info.append(\n",
    "                [\n",
    "                    int(auth['authid']),\n",
    "                    auth['given-name'],\n",
    "                    auth['surname'],\n",
    "                    auth['initials'],\n",
    "                    auth['author-url'],\n",
    "                    None, # sex\n",
    "                    None, # type\n",
    "                    None, # rank\n",
    "                    None, # email\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            paper_author_info.append(\n",
    "                [\n",
    "                    paper_info[0],\n",
    "                    int(auth['authid']),\n",
    "                    auth['@seq'],\n",
    "                ]\n",
    "            )\n",
    "        db.commit()\n",
    "db.close()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['search-results']['entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
