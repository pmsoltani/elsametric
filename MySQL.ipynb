{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as read_file:\n",
    "    client = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000002358A00D3C8>\n"
     ]
    }
   ],
   "source": [
    "db = mysql.connect(\n",
    "    host = 'localhost',\n",
    "    buffered = True,\n",
    "    user = client['MySQL User'],\n",
    "    passwd = client['MySQL Pass'],\n",
    "    database = 'scopus'\n",
    ")\n",
    "\n",
    "# column names\n",
    "subject_col = ['asjc_code', 'top', 'middle', 'low']\n",
    "source_col = ['source_id_scp', 'title', 'url', 'type', 'issn', 'e_issn', 'isbn', 'publisher', 'country']\n",
    "source_subject_col = ['source_id', 'subject_id']\n",
    "paper_col = ['paper_id_scp', 'eid', 'title', 'type', 'type_description', 'abstract', 'total_author', 'open_access', 'cited_cnt', 'url', 'article_no', 'fund_no', 'retrieval_time', 'source_id', 'doi', 'volume', 'issue', 'date', 'page_range']\n",
    "author_col = ['author_id_scp', 'first', 'last', 'initials', 'sex', 'type', 'rank', 'email',]\n",
    "paper_author_col = ['paper_id', 'author_id', 'author_no']\n",
    "author_profile_col = ['author_id', 'url', 'type']\n",
    "department_col = ['department_id', 'name', 'abbreviation', 'type', 'lat', 'lng']\n",
    "author_department_col = ['author_id', 'department_id']\n",
    "institution_col = ['institution_id_scp', 'name', 'abbreviation', 'city', 'country', 'url', 'type', 'lat', 'lng']\n",
    "department_institution_col = ['department_id', 'institution_id']\n",
    "\n",
    "subject_q = '''INSERT INTO subject (asjc_code, top, middle, low) VALUES (%s, %s, %s, %s)'''\n",
    "source_q = '''INSERT INTO source (source_id_scp, title, url, type, issn, e_issn, isbn, publisher, country) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "source_subject_q = '''INSERT INTO source_subject (source_id, subject_id) VALUES (%s, %s)'''\n",
    "paper_q = '''INSERT INTO paper (paper_id_scp, eid, title, type, type_description, abstract, total_author, open_access, cited_cnt, url, article_no, fund_no, retrieval_time, source_id, doi, volume, issue, date, page_range) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "author_q = '''INSERT INTO author (author_id_scp, first, last, initials, sex, type, rank, email) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "paper_author_q = '''INSERT INTO paper_author (paper_id, author_id, author_no) VALUES (%s, %s, %s)'''\n",
    "author_profile_q = '''INSERT INTO author_profile (author_id, url, type) VALUES (%s, %s, %s)'''\n",
    "department_q = '''INSERT INTO department (department_id, name, abbreviation, type, lat, lng) VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "author_department_q = '''INSERT INTO author_department (author_id, department_id) VALUES (%s, %s)'''\n",
    "institution_q = '''INSERT INTO institution (institution_id_scp, name, abbreviation, city, country, url, type, lat, lng) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "department_institution_q = '''INSERT INTO department_institution (department_id, institution_id) VALUES (%s, %s)'''\n",
    "\n",
    "cols = [\n",
    "    subject_col, source_col, source_subject_col, paper_col, author_col, \n",
    "    paper_author_col, author_profile_col, department_col, author_department_col, \n",
    "    institution_col, department_institution_col\n",
    "]\n",
    "\n",
    "col_names = [\n",
    "    'subject', 'source', 'source_subject', 'paper', 'author', \n",
    "    'paper_author', 'author_profile', 'department', 'author_department', \n",
    "    'institution', 'department_institution'\n",
    "]\n",
    "\n",
    "for name, col, que in zip(col_names, cols, ques):\n",
    "    table_name = name\n",
    "    table_col = col\n",
    "    q = f'INSERT INTO {table_name} ({\", \".join(table_col)}) VALUES ({\"%s, \" * (len(table_col) - 1)}%s)'\n",
    "\n",
    "print(db)\n",
    "cursor = db.cursor()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "\n",
    "with io.open(os.path.join(path, files[0]), 'r', encoding='utf8') as raw:\n",
    "    data = json.load(raw)\n",
    "\n",
    "faculties = []\n",
    "with io.open('data\\\\faculties.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        if row['Scopus']:\n",
    "            row['Scopus'] = list(map(int, row['Scopus'].split(',')))\n",
    "        faculties.append(row)\n",
    "\n",
    "asjc = []\n",
    "with io.open('data\\\\ASJC Codes.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        asjc.append(row)\n",
    "\n",
    "sources = []\n",
    "with io.open('data\\\\Scopus Sources.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        row.pop('Active', None)\n",
    "        row.pop('Discontinued', None)\n",
    "        row.pop('Coverage', None)\n",
    "        row.pop('2016 CiteScore', None)\n",
    "        row.pop('2017 CiteScore', None)\n",
    "        row.pop('2018 CiteScore', None)\n",
    "        row.pop('Medline-sourced', None)\n",
    "        row.pop('Open Access', None)\n",
    "        row.pop('Articles in Press Included', None)\n",
    "        row.pop('Added to list April 2019', None)\n",
    "        row.pop('Title history indication', None)\n",
    "        row.pop('Related title to title history indication', None)\n",
    "        row.pop('Other related title 1', None)\n",
    "        row.pop('Other related title 2', None)\n",
    "        row.pop('Other related title 3', None)\n",
    "        row.pop('Publisher imprints grouped to main Publisher', None)\n",
    "        \n",
    "        row['ASJC'] = [int(code) for code in row['ASJC'].split(';') if code != '']\n",
    "        sources.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "#     print(file)\n",
    "    year = file.split('.')[0].split('_')[-4][1:]\n",
    "    with io.open(os.path.join(path, file), 'r', encoding='utf8') as raw:\n",
    "        data = json.load(raw)\n",
    "    data = data['search-results']['entry']\n",
    "    for paper in data:\n",
    "        print(int(paper['dc:identifier'].split(':')[1]))\n",
    "        rnd_source = random.randint(100000,200000)\n",
    "        source_info = [\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:publicationName'] if 'prism:publicationName' in paper.keys() else 'No Name!'),\n",
    "            'https://www.scopus.com/sourceid/', # url\n",
    "            (paper['prism:issn'] if 'prism:issn' in paper.keys() else None),\n",
    "            (paper['prism:isbn'][0]['$'] if 'prism:isbn' in paper.keys() else None),\n",
    "            None, # **subject\n",
    "            None, # **publisher\n",
    "            (paper['prism:aggregationType'] if 'prism:aggregationType' in paper.keys() else None),\n",
    "        ]\n",
    "        cursor.execute(source_q, source_info)\n",
    "        \n",
    "        paper_info = [\n",
    "            int(paper['dc:identifier'].split(':')[1]),\n",
    "            paper['eid'],\n",
    "            paper['dc:title'],\n",
    "            (paper['subtype'] if 'subtype' in paper.keys() else None),\n",
    "            (paper['subtypeDescription'] if 'subtypeDescription' in paper.keys() else None),\n",
    "            (paper['dc:description'] if 'dc:description' in paper.keys() else None),\n",
    "            paper['author-count']['$'],\n",
    "            (paper['openaccess'] if 'openaccess' in paper.keys() else None),\n",
    "            paper['citedby-count'],\n",
    "            paper['link'][-2]['@href'],\n",
    "            (paper['article-number'] if 'article-number' in paper.keys() else None),\n",
    "            (paper['fund-no'] if 'fund-no' in paper.keys() else None),\n",
    "            datetime.utcfromtimestamp(int(file.split('.')[0].split('_')[-1])).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:doi'] if 'prism:doi' in paper.keys() else None),\n",
    "            (paper['prism:volume'] if 'prism:volume' in paper.keys() else None),\n",
    "            (paper['prism:issueIdentifier'] if 'prism:issueIdentifier' in paper.keys() else None),\n",
    "            (datetime.strptime(paper['prism:coverDate'], '%Y-%m-%d').strftime('%Y-%m-%d') if 'prism:coverDate' in paper.keys() else year),\n",
    "            (paper['prism:pageRange'] if 'prism:pageRange' in paper.keys() else None),\n",
    "        ]\n",
    "#         cursor.execute(paper_q, paper_info)\n",
    "        \n",
    "        author_info = []\n",
    "        paper_author_info = []\n",
    "        for auth in paper['author']:\n",
    "            author_info.append(\n",
    "                [\n",
    "                    int(auth['authid']),\n",
    "                    auth['given-name'],\n",
    "                    auth['surname'],\n",
    "                    auth['initials'],\n",
    "                    auth['author-url'],\n",
    "                    None, # sex\n",
    "                    None, # type\n",
    "                    None, # rank\n",
    "                    None, # email\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            paper_author_info.append(\n",
    "                [\n",
    "                    paper_info[0],\n",
    "                    int(auth['authid']),\n",
    "                    auth['@seq'],\n",
    "                ]\n",
    "            )\n",
    "        db.commit()\n",
    "db.close()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \n",
    "    table_ids = {\n",
    "        'source': {'order': 0, 'id': ['source_id_scp']},\n",
    "        'subject': {'order': 0, 'id': ['asjc_code']},\n",
    "        'country': {'order': 0, 'id': ['country_id']},\n",
    "        'paper_funding': {'order': 0, 'id': ['agency_id_scp']},\n",
    "        \n",
    "        'source_subject': {'order': 1, 'id': ['source_id', 'subject_id']},\n",
    "        'paper': {'order': 1, 'id': ['paper_id_scp']},\n",
    "        \n",
    "        'author': {'order': 2, 'id': ['author_id_scp']},\n",
    "        'keyword': {'order': 2, 'id': ['keyword_id']},\n",
    "        \n",
    "        'paper_author': {'order': 3, 'id': ['paper_id', 'author_id']},\n",
    "        'paper_keyword': {'order': 3, 'id': ['paper_id', 'keyword_id']},\n",
    "        'department': {'order': 3, 'id': ['department_id']},\n",
    "        'author_profile': {'order': 3, 'id': ['profile_id', 'author_id']},\n",
    "        \n",
    "        'author_department': {'order': 4, 'id': ['author_id', 'department_id']},\n",
    "        'institution': {'order': 4, 'id': ['institution_id_scp']},\n",
    "        \n",
    "        'department_institution': {'order': 5, 'id': ['department_id', 'institution_id']},\n",
    "    }\n",
    "    \n",
    "    def __init__(self, config: dict, db_name: str, host: str = 'localhost', port: int = 3306, buffered: bool = True):\n",
    "        print('@ __init__')\n",
    "        self._params = {\n",
    "            'host': host,\n",
    "            'buffered': buffered,\n",
    "            'user': config['MySQL User'],\n",
    "            'pass': config['MySQL Pass'],\n",
    "        }\n",
    "        self.db_name = db_name\n",
    "        self.db = None\n",
    "        self.cursor = None\n",
    "        self.tables = []\n",
    "        print('__init__ done!')\n",
    "    \n",
    "    def _connect(self):\n",
    "        print('@ _connect')\n",
    "        if not self.db:\n",
    "            self.db = mysql.connect(\n",
    "                host = self._params['host'],\n",
    "                buffered = self._params['buffered'],\n",
    "                user = self._params['user'],\n",
    "                password = self._params['pass'],\n",
    "                database = self.db_name\n",
    "            )\n",
    "        print('_connect done!')\n",
    "        return self.db\n",
    "    \n",
    "    def _cursor(self):\n",
    "        print('@ _cursor')\n",
    "        if not self.db:\n",
    "            self._connect()\n",
    "        if not self.db.is_connected():\n",
    "            self.db.reconnect()\n",
    "        if not self.cursor:\n",
    "            self.cursor = self.db.cursor()\n",
    "        print('_cursor done!')\n",
    "        return self.cursor\n",
    "    \n",
    "    def _execute(self, query, values = [], fetch: bool = False, many: bool = False, close_cursor: bool = False):\n",
    "        print('@ _execute')\n",
    "        if many:\n",
    "            self._cursor().executemany(query, values)\n",
    "        else:\n",
    "            self._cursor().execute(query, values)\n",
    "        if fetch:\n",
    "            server_response = self.cursor.fetchall()\n",
    "        else:\n",
    "            server_response = self.cursor\n",
    "        print('_execute done!')\n",
    "        if close_cursor:\n",
    "            self.cursor.close()\n",
    "            self.cursor = None\n",
    "        return server_response\n",
    "    \n",
    "    def _close(self):\n",
    "        print('@ _close')\n",
    "        if self.db.is_connected():\n",
    "            self.db.close()\n",
    "        print('Closed!')\n",
    "    \n",
    "    def _show_tables(self):\n",
    "        print('@ _show_tables')\n",
    "        return [table[0] for table in self._execute(query = 'SHOW TABLES', fetch = True)]\n",
    "    \n",
    "    def _has_table(self, table_name):\n",
    "        print('@ _has_table')\n",
    "        table_names = self._show_tables()\n",
    "        if table_name in table_names:\n",
    "            print('_has_table done!')\n",
    "            return True\n",
    "        print('_has_table done!')\n",
    "        return False\n",
    "    \n",
    "    def _column_names(self, table_name):\n",
    "        print('@ _column_names')\n",
    "        return [col[0] for col in self.describe(table_name)]\n",
    "    \n",
    "    def describe(self, table_name: str = ''):\n",
    "        print('@ describe')\n",
    "        if table_name:\n",
    "            query = f'DESCRIBE {table_name}'\n",
    "            print('describe done!')\n",
    "            return self._execute(query = query, fetch = True)\n",
    "        server_response = self._show_tables()\n",
    "        for table in server_response:\n",
    "            self.tables.append({table: self.describe(table)})\n",
    "        print('describe done!')\n",
    "        return self.tables\n",
    "    \n",
    "    def _read(self, table_name: str, search: dict, select = '*', result_columns: bool = False):\n",
    "        print('@ _read')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        if search:\n",
    "            query = (f'SELECT {select} FROM {table_name} WHERE ' \n",
    "                + ' AND '.join([f'{k} {v[\"operator\"]} {v[\"value\"]}' for k, v in search.items()]))\n",
    "        else:\n",
    "            query = f'SELECT {select} FROM {table_name}'\n",
    "        server_response = self._execute(query = query, fetch = True, close_cursor = True)\n",
    "        print('got the response from _execute')\n",
    "        if result_columns:\n",
    "            result = []\n",
    "            if select == '*':\n",
    "                column_names = self._column_names(table_name)\n",
    "            else:\n",
    "                column_names = [column.strip() for column in select.split(',')]\n",
    "            for row in server_response:\n",
    "                result.append({name: value for name, value in zip(column_names, row)})\n",
    "            print('_read done!')\n",
    "            return result\n",
    "        print('_read done!')\n",
    "        return server_response\n",
    "    \n",
    "    # def has_row(self, table_name, row_ids: dict):\n",
    "    #     print('@ has_row')\n",
    "    #     search = {}\n",
    "    #     for row_id in row_ids:\n",
    "    #         search[row_id] = {'value': row_ids[row_id], 'operator': '='}\n",
    "    #     server_response = self._read(table_name, search, select = 'COUNT(*)')\n",
    "    #     print('has_row done!')\n",
    "    #     return server_response[0][0]\n",
    "    \n",
    "    def _insert_one(self, table_name, data: dict):\n",
    "        # data is a list of dictionaries\n",
    "        print('@ _insert_one')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        table_columns = self._column_names(table_name)\n",
    "        data_columns = list(data.keys())\n",
    "        for col in data_columns:\n",
    "            if col not in table_columns:\n",
    "                return f'Error! \"{col}\" column not found'\n",
    "        \n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(data_columns)}) VALUES ({\"%s, \" * (len(data_columns) - 1)}%s)'\n",
    "        \n",
    "        # check if the record already exists\n",
    "        id_columns = Database.table_ids[table_name]['id']\n",
    "        search = {id_column: {'value': data[id_column], 'operator': '='} for id_column in id_columns}\n",
    "        print(search)\n",
    "        server_response = self._read(table_name, search)\n",
    "        if server_response: # record exists, let's return the its primary key\n",
    "            server_response = server_response[-1][0]\n",
    "            return {'msg': f'Table \"{table_name}\" already has this record', 'value': server_response}\n",
    "        \n",
    "        # record is new\n",
    "        values = tuple(data[col] for col in data_columns)\n",
    "        try:\n",
    "            self._execute(query, values)\n",
    "            print('_insert_one done!')\n",
    "            self.db.commit()\n",
    "            last_id = self.cursor.lastrowid\n",
    "            self._close()\n",
    "            return {'msg': f'Record added to \"{table_name}\"', 'value': last_id}\n",
    "        except Exception as e:\n",
    "            print(f'error here: {e}')\n",
    "            self._close()\n",
    "        \n",
    "    def _insert_many(self, table_name, data: list):\n",
    "        # data is a list of dictionaries\n",
    "        print('@ _insert')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        # assuming all data rows have the same columns\n",
    "        # data is a list of dictionaries, of which the keys are column names\n",
    "        table_columns = self._column_names(table_name)\n",
    "        data_columns = list(data[0].keys())\n",
    "        for col in data_columns:\n",
    "            if col not in table_columns:\n",
    "                return f'Error! \"{col}\" column not found'\n",
    "        \n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(data_columns)}) VALUES ({\"%s, \" * (len(data_columns) - 1)}%s)'\n",
    "        values = []\n",
    "        id_columns = Database.table_ids[table_name]['id']\n",
    "        skipped_rows = 0\n",
    "        total_rows = len(data)\n",
    "        for row in data:\n",
    "            search = {id_column: {'value': row[id_column], 'operator': '='} for id_column in id_columns}\n",
    "            if self._read(table_name, search):\n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "            values.append(tuple(row[col] for col in data_columns))\n",
    "        try:\n",
    "            self._execute(query, values, many = True)\n",
    "            print('_insert done!')\n",
    "            self.db.commit()\n",
    "            last_id = self.cursor.lastrowid\n",
    "            self._close()\n",
    "            return {'msg': f'{total_rows - skipped_rows} records added ({skipped_rows} already existed)', 'value': last_id}\n",
    "        except Exception as e:\n",
    "            print(f'error here: {e}')\n",
    "            self._close()\n",
    "    \n",
    "    def raw_insert(self, data: list, retrieval_time):\n",
    "        print('@ raw_insert')\n",
    "        # data is a dictionary containing the info about 1 paper\n",
    "        warnings = data_inspector(data)\n",
    "        if 'openaccess' in warnings:\n",
    "            data['openaccess'] = '0'\n",
    "            warnings.pop('openaccess')\n",
    "        if 'author:afid' in warnings:\n",
    "            warnings.pop('author:afid')\n",
    "        if len(warnings):\n",
    "            return {'warnings': warnings}\n",
    "        \n",
    "        keys = data.keys()\n",
    "        \n",
    "        paper_url = ''\n",
    "        for link in data['link']:\n",
    "            if link['@ref'] == 'scopus':\n",
    "                paper_url = link['@href']\n",
    "                break\n",
    "\n",
    "        paper_id_scp = int(data['dc:identifier'].split(':')[1])\n",
    "        if self._read('paper', {'paper_id_scp': {'value': paper_id_scp, 'operator': '='}}):\n",
    "            return {'warnings': ['paper exists']}\n",
    "        \n",
    "        source_id_scp = int(data['source-id'])\n",
    "        agency_id_scp = key_get(data, keys, 'fund-no')\n",
    "        if agency_id_scp == 'undefined':\n",
    "            agency_id_scp = None\n",
    "        \n",
    "        source_info = {\n",
    "            'source_id_scp': source_id_scp, \n",
    "            'title': data['prism:publicationName'], \n",
    "            'url': f'https://www.scopus.com/sourceid/{source_id_scp}', \n",
    "            'type': key_get(data, keys, 'prism:aggregationType'), \n",
    "            'issn': key_get(data, keys, 'prism:issn'), \n",
    "            'e_issn': key_get(data, keys, 'prism:eIssn'), \n",
    "            'isbn': key_get(data, keys, 'prism:isbn'), \n",
    "            'publisher': None, \n",
    "            'country_id': None\n",
    "        }\n",
    "        \n",
    "        source_id = self._insert_one('source', source_info)['value']\n",
    "        \n",
    "        agency_id = None\n",
    "        if agency_id_scp:\n",
    "            paper_funding_info = {\n",
    "                'agency_id_scp': key_get(data, keys, 'fund-no'), \n",
    "                'agency':  key_get(data, keys, 'fund-sponsor'), \n",
    "                'agency_acronym': key_get(data, keys, 'fund-acr'), \n",
    "            }\n",
    "            agency_id = self._insert_one('paper_funding', paper_funding_info)['value']            \n",
    "            \n",
    "        paper_info = {\n",
    "            'paper_id_scp': paper_id_scp,\n",
    "            'eid': data['eid'],\n",
    "            'title': data['dc:title'],\n",
    "            'type': data['subtype'],\n",
    "            'type_description': key_get(data, keys, 'subtypeDescription'),\n",
    "            'abstract': key_get(data, keys, 'dc:description'),\n",
    "            'total_author': key_get(data, keys, 'author-count'),\n",
    "            'open_access': data['openaccess'],\n",
    "            'cited_cnt': data['citedby-count'],\n",
    "            'url': paper_url,\n",
    "            'article_no': key_get(data, keys, 'prism:volume'),\n",
    "            'agency_id': agency_id,\n",
    "            'retrieval_time': retrieval_time,\n",
    "            'source_id': source_id,\n",
    "            'doi': key_get(data, keys, 'prism:doi'),\n",
    "            'volume': key_get(data, keys, 'prism:volume'),\n",
    "            'issue': key_get(data, keys, 'prism:issueIdentifier'),\n",
    "            'page_range': key_get(data, keys, 'prism:pageRange'),\n",
    "            'date': data['prism:coverDate'],\n",
    "        }\n",
    "        \n",
    "        paper_id = self._insert_one('paper', paper_info)['value']\n",
    "        print('raw_insert done')\n",
    "        return [source_id, agency_id, paper_id]\n",
    "#             'author': {},\n",
    "#             'keyword': {},\n",
    "#             'paper_author': {},\n",
    "#             'paper_keyword': {},\n",
    "#             'author_profile': {},\n",
    "#             'department': {},\n",
    "#             'author_department': {},\n",
    "#             'institution': {},\n",
    "#             'department_institution': {},\n",
    "#         }\n",
    "\n",
    "#         author_info = []\n",
    "#         paper_author_info = []\n",
    "#         for author in data['author']:\n",
    "#             keys = author.keys()\n",
    "#             author_id = int(author['authid'])\n",
    "#             author_info.append(\n",
    "#                 {\n",
    "#                     'author_id_scp': author_id,\n",
    "#                     'first': key_get(author, keys, 'given-name'),\n",
    "#                     'last': key_get(author, keys, 'surname'),\n",
    "#                     'initials' key_get(author, keys, 'initials'),\n",
    "#                     # f'https://www.scopus.com/authid/detail.uri?authorId={auth[\"authid\"]},\n",
    "#                 }\n",
    "#             )\n",
    "#             paper_author_info.append(\n",
    "#                 {\n",
    "#                     'paper_id': None, # paper_id\n",
    "#                     'author_id': None, # author_id\n",
    "#                     'author_no': int(author['@seq']),\n",
    "#                 }\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_inspector(data: dict):\n",
    "    warnings = []\n",
    "    top_keys = [\n",
    "        'source-id', 'prism:publicationName', 'prism:coverDate',\n",
    "        'dc:identifier', 'eid', 'dc:title', 'subtype', 'author-count', 'openaccess', 'citedby-count', 'link', \n",
    "        'author', 'affiliation',\n",
    "    ]\n",
    "    author_keys = ['authid', '@seq', 'afid']\n",
    "    affiliation_keys = ['afid', 'affilname']\n",
    "    \n",
    "    keys = data.keys()\n",
    "    for key in top_keys:\n",
    "        if key not in keys:\n",
    "            warnings.append(key)\n",
    "    if 'link' not in warnings:\n",
    "        if all(link['@ref'] != 'scopus' for link in data['link']):\n",
    "            warnings.append('paper url')\n",
    "    if 'author' not in warnings:\n",
    "        for author in data['author']:\n",
    "            keys = author.keys()\n",
    "            for key in author_keys:\n",
    "                if key not in keys:\n",
    "                    warnings.append(f'author:{key}')\n",
    "    if 'affiliation' not in warnings:\n",
    "        for affiliation in data['affiliation']:\n",
    "            keys = affiliation.keys()\n",
    "            for key in affiliation_keys:\n",
    "                if key not in keys:\n",
    "                    warnings.append(f'affiliation:{key}')\n",
    "    return warnings\n",
    "\n",
    "def key_get(data: dict, keys, key: str):\n",
    "    result = (data[key] if key in keys else None)\n",
    "    if type(result) == list:\n",
    "        return result[0]['$']\n",
    "    if type(result) == dict:\n",
    "        return result['$']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ __init__\n",
      "__init__ done!\n",
      "@ _insert\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "@ _connect\n",
      "_connect done!\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _column_names\n",
      "@ describe\n",
      "describe done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "@ _read\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "got the response from _execute\n",
      "_read done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_insert done!\n",
      "@ _close\n",
      "Closed!\n",
      "@ _close\n",
      "Closed!\n"
     ]
    }
   ],
   "source": [
    "d = Database(config = client, db_name = 'scopus')\n",
    "d._insert_many('paper_funding', [{'agency_id_scp': 27, 'agency': 'FQatar', 'agency_acronym': 'QNSF'}])#,{'agency_id_scp': 13, 'agency': 'US', 'agency_acronym': 'NSF'}])\n",
    "# d._insert_many('source_subject', [{'source_id': 2, 'subject_id': 2},{'subject_id': 3, 'source_id': 1}])\n",
    "# d._read('paper_funding', {'agency_id_scp': {'value': 20, 'operator': '='}}, result_columns=True)\n",
    "# d._insert_one('paper_funding', {'agency_id_scp': 21, 'agency': 'FQatar', 'agency_acronym': 'QNSF'})#,{'agency_id_scp': 13, 'agency': 'US', 'agency_acronym': 'NSF'}])\n",
    "# d._read('source_subject', {'source_id': {'value': 1, 'operator': '='}, 'subject_id': {'value': 3, 'operator': '='}}, result_columns=True)\n",
    "# d.has_row('paper_funding', [['agency_id',13]])\n",
    "# d._table_order()\n",
    "# print(d.describe('subject'))\n",
    "d._close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ __init__\n",
      "__init__ done!\n",
      "@ raw_insert\n",
      "@ _read\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "@ _connect\n",
      "_connect done!\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "got the response from _execute\n",
      "_read done!\n",
      "@ _insert_one\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _column_names\n",
      "@ describe\n",
      "describe done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "{'source_id_scp': {'value': 21100828963, 'operator': '='}}\n",
      "@ _read\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "got the response from _execute\n",
      "_read done!\n",
      "@ _insert_one\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _column_names\n",
      "@ describe\n",
      "describe done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "{'paper_id_scp': {'value': 85059543553, 'operator': '='}}\n",
      "@ _read\n",
      "@ _has_table\n",
      "@ _show_tables\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_has_table done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "got the response from _execute\n",
      "_read done!\n",
      "@ _execute\n",
      "@ _cursor\n",
      "_cursor done!\n",
      "_execute done!\n",
      "_insert_one done!\n",
      "@ _close\n",
      "Closed!\n",
      "raw_insert done\n",
      "[5, None, 2]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "cnt = 0\n",
    "db = Database(config = client, db_name = 'scopus')\n",
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "for file in files[:1]:\n",
    "    with io.open(os.path.join(path, file), 'r', encoding='utf8') as raw:\n",
    "        data = json.load(raw)\n",
    "    data = data['search-results']['entry']\n",
    "    ret_time = datetime.utcfromtimestamp(int(file.split('.')[0].split('_')[-1])).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for paper in data[:1]:\n",
    "        warnings = data_inspector(paper)\n",
    "        ins_id = db.raw_insert(paper, retrieval_time=ret_time)\n",
    "print(ins_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
