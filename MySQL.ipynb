{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import json\n",
    "\n",
    "with open('config.json', 'r') as read_file:\n",
    "    client = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000002358A00D3C8>\n"
     ]
    }
   ],
   "source": [
    "db = mysql.connect(\n",
    "    host = 'localhost',\n",
    "    buffered = True,\n",
    "    user = client['MySQL User'],\n",
    "    passwd = client['MySQL Pass'],\n",
    "    database = 'scopus'\n",
    ")\n",
    "\n",
    "# column names\n",
    "subject_col = ['asjc_code', 'top', 'middle', 'low']\n",
    "source_col = ['source_id_scp', 'title', 'url', 'type', 'issn', 'e_issn', 'isbn', 'publisher', 'country']\n",
    "source_subject_col = ['source_id', 'subject_id']\n",
    "paper_col = ['paper_id_scp', 'eid', 'title', 'type', 'type_description', 'abstract', 'total_author', 'open_access', 'cited_cnt', 'url', 'article_no', 'fund_no', 'retrieval_time', 'source_id', 'doi', 'volume', 'issue', 'date', 'page_range']\n",
    "author_col = ['author_id_scp', 'first', 'last', 'initials', 'sex', 'type', 'rank', 'email',]\n",
    "paper_author_col = ['paper_id', 'author_id', 'author_no']\n",
    "author_profile_col = ['author_id', 'url', 'type']\n",
    "department_col = ['department_id', 'name', 'abbreviation', 'type', 'lat', 'lng']\n",
    "author_department_col = ['author_id', 'department_id']\n",
    "institution_col = ['institution_id_scp', 'name', 'abbreviation', 'city', 'country', 'url', 'type', 'lat', 'lng']\n",
    "department_institution_col = ['department_id', 'institution_id']\n",
    "\n",
    "subject_q = '''INSERT INTO subject (asjc_code, top, middle, low) VALUES (%s, %s, %s, %s)'''\n",
    "source_q = '''INSERT INTO source (source_id_scp, title, url, type, issn, e_issn, isbn, publisher, country) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "source_subject_q = '''INSERT INTO source_subject (source_id, subject_id) VALUES (%s, %s)'''\n",
    "paper_q = '''INSERT INTO paper (paper_id_scp, eid, title, type, type_description, abstract, total_author, open_access, cited_cnt, url, article_no, fund_no, retrieval_time, source_id, doi, volume, issue, date, page_range) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "author_q = '''INSERT INTO author (author_id_scp, first, last, initials, sex, type, rank, email) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "paper_author_q = '''INSERT INTO paper_author (paper_id, author_id, author_no) VALUES (%s, %s, %s)'''\n",
    "author_profile_q = '''INSERT INTO author_profile (author_id, url, type) VALUES (%s, %s, %s)'''\n",
    "department_q = '''INSERT INTO department (department_id, name, abbreviation, type, lat, lng) VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "author_department_q = '''INSERT INTO author_department (author_id, department_id) VALUES (%s, %s)'''\n",
    "institution_q = '''INSERT INTO institution (institution_id_scp, name, abbreviation, city, country, url, type, lat, lng) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "department_institution_q = '''INSERT INTO department_institution (department_id, institution_id) VALUES (%s, %s)'''\n",
    "\n",
    "cols = [\n",
    "    subject_col, source_col, source_subject_col, paper_col, author_col, \n",
    "    paper_author_col, author_profile_col, department_col, author_department_col, \n",
    "    institution_col, department_institution_col\n",
    "]\n",
    "\n",
    "col_names = [\n",
    "    'subject', 'source', 'source_subject', 'paper', 'author', \n",
    "    'paper_author', 'author_profile', 'department', 'author_department', \n",
    "    'institution', 'department_institution'\n",
    "]\n",
    "\n",
    "for name, col, que in zip(col_names, cols, ques):\n",
    "    table_name = name\n",
    "    table_col = col\n",
    "    q = f'INSERT INTO {table_name} ({\", \".join(table_col)}) VALUES ({\"%s, \" * (len(table_col) - 1)}%s)'\n",
    "\n",
    "print(db)\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DESCRIBE %s', 'author')\n",
    "databases = cursor.fetchall()\n",
    "for database in databases:\n",
    "    print(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = (1358,'Chem Proceedings','https://www.google.com',12345678,123,'ChE','Sharif','Journal')\n",
    "cursor.execute(source_q, values)\n",
    "db.commit()\n",
    "\n",
    "print(cursor.rowcount, \"record inserted\")\n",
    "db.close()\n",
    "# cursor.execute(paper_q, (123,4345,'awef','ar','','',1,1,1,'wef','','','2001-12-12 12:13:24','2038-01-19 03:14:07',1356,'','','','2008-05-06',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "\n",
    "with io.open(os.path.join(path, files[0]), 'r', encoding='utf8') as raw:\n",
    "    data = json.load(raw)\n",
    "\n",
    "faculties = []\n",
    "with io.open('data\\\\faculties.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        if row['Scopus']:\n",
    "            row['Scopus'] = list(map(int, row['Scopus'].split(',')))\n",
    "        faculties.append(row)\n",
    "\n",
    "asjc = []\n",
    "with io.open('data\\\\ASJC Codes.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        asjc.append(row)\n",
    "\n",
    "sources = []\n",
    "with io.open('data\\\\Scopus Sources.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        row.pop('Active', None)\n",
    "        row.pop('Discontinued', None)\n",
    "        row.pop('Coverage', None)\n",
    "        row.pop('2016 CiteScore', None)\n",
    "        row.pop('2017 CiteScore', None)\n",
    "        row.pop('2018 CiteScore', None)\n",
    "        row.pop('Medline-sourced', None)\n",
    "        row.pop('Open Access', None)\n",
    "        row.pop('Articles in Press Included', None)\n",
    "        row.pop('Added to list April 2019', None)\n",
    "        row.pop('Title history indication', None)\n",
    "        row.pop('Related title to title history indication', None)\n",
    "        row.pop('Other related title 1', None)\n",
    "        row.pop('Other related title 2', None)\n",
    "        row.pop('Other related title 3', None)\n",
    "        row.pop('Publisher imprints grouped to main Publisher', None)\n",
    "        \n",
    "        row['ASJC'] = [int(code) for code in row['ASJC'].split(';') if code != '']\n",
    "        sources.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "#     print(file)\n",
    "    year = file.split('.')[0].split('_')[-4][1:]\n",
    "    with io.open(os.path.join(path, file), 'r', encoding='utf8') as raw:\n",
    "        data = json.load(raw)\n",
    "    data = data['search-results']['entry']\n",
    "    for paper in data:\n",
    "        print(int(paper['dc:identifier'].split(':')[1]))\n",
    "        rnd_source = random.randint(100000,200000)\n",
    "        source_info = [\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:publicationName'] if 'prism:publicationName' in paper.keys() else 'No Name!'),\n",
    "            'https://www.scopus.com/sourceid/', # url\n",
    "            (paper['prism:issn'] if 'prism:issn' in paper.keys() else None),\n",
    "            (paper['prism:isbn'][0]['$'] if 'prism:isbn' in paper.keys() else None),\n",
    "            None, # **subject\n",
    "            None, # **publisher\n",
    "            (paper['prism:aggregationType'] if 'prism:aggregationType' in paper.keys() else None),\n",
    "        ]\n",
    "        cursor.execute(source_q, source_info)\n",
    "        \n",
    "        paper_info = [\n",
    "            int(paper['dc:identifier'].split(':')[1]),\n",
    "            paper['eid'],\n",
    "            paper['dc:title'],\n",
    "            (paper['subtype'] if 'subtype' in paper.keys() else None),\n",
    "            (paper['subtypeDescription'] if 'subtypeDescription' in paper.keys() else None),\n",
    "            (paper['dc:description'] if 'dc:description' in paper.keys() else None),\n",
    "            paper['author-count']['$'],\n",
    "            (paper['openaccess'] if 'openaccess' in paper.keys() else None),\n",
    "            paper['citedby-count'],\n",
    "            paper['link'][-2]['@href'],\n",
    "            (paper['article-number'] if 'article-number' in paper.keys() else None),\n",
    "            (paper['fund-no'] if 'fund-no' in paper.keys() else None),\n",
    "            datetime.utcfromtimestamp(int(file.split('.')[0].split('_')[-1])).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            (int(paper['source-id']) if 'source-id' in paper.keys() else rnd_source),\n",
    "            (paper['prism:doi'] if 'prism:doi' in paper.keys() else None),\n",
    "            (paper['prism:volume'] if 'prism:volume' in paper.keys() else None),\n",
    "            (paper['prism:issueIdentifier'] if 'prism:issueIdentifier' in paper.keys() else None),\n",
    "            (datetime.strptime(paper['prism:coverDate'], '%Y-%m-%d').strftime('%Y-%m-%d') if 'prism:coverDate' in paper.keys() else year),\n",
    "            (paper['prism:pageRange'] if 'prism:pageRange' in paper.keys() else None),\n",
    "        ]\n",
    "#         cursor.execute(paper_q, paper_info)\n",
    "        \n",
    "        author_info = []\n",
    "        paper_author_info = []\n",
    "        for auth in paper['author']:\n",
    "            author_info.append(\n",
    "                [\n",
    "                    int(auth['authid']),\n",
    "                    auth['given-name'],\n",
    "                    auth['surname'],\n",
    "                    auth['initials'],\n",
    "                    auth['author-url'],\n",
    "                    None, # sex\n",
    "                    None, # type\n",
    "                    None, # rank\n",
    "                    None, # email\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            paper_author_info.append(\n",
    "                [\n",
    "                    paper_info[0],\n",
    "                    int(auth['authid']),\n",
    "                    auth['@seq'],\n",
    "                ]\n",
    "            )\n",
    "        db.commit()\n",
    "db.close()\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['search-results']['entry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for code in asjc:\n",
    "    subject_info = [\n",
    "        code['Code'],\n",
    "        code['Top'],\n",
    "        code['Middle'],\n",
    "        code['Low'],\n",
    "    ]\n",
    "    cursor.execute(subject_q, subject_info)\n",
    "print('Done!')\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self, config: dict, db_name: str, host: str = 'localhost', buffered: bool = True):\n",
    "        self._params = {\n",
    "            'host': host,\n",
    "            'buffered': buffered,\n",
    "            'user': config['MySQL User'],\n",
    "            'pass': config['MySQL Pass'],\n",
    "        }\n",
    "        self.db_name = db_name\n",
    "        self.db = None\n",
    "        self.cursor = None\n",
    "        self.tables = []\n",
    "    \n",
    "    def _connect(self):\n",
    "        if not self.db:\n",
    "            self.db = mysql.connect(\n",
    "                host = self._params['host'],\n",
    "                buffered = self._params['buffered'],\n",
    "                user = self._params['user'],\n",
    "                passwd = self._params['pass'],\n",
    "                database = self.db_name\n",
    "            )\n",
    "        return self.db\n",
    "    \n",
    "    def _cursor(self):\n",
    "        if not self.cursor:\n",
    "            self.cursor = self._connect().cursor()\n",
    "        return self.cursor\n",
    "    \n",
    "    def _execute(self, query, values = [], fetch: bool = False, many: bool = False):\n",
    "        if many:\n",
    "            self._cursor().executemany(query, values)\n",
    "        else:\n",
    "            self._cursor().execute(query, values)\n",
    "        if fetch:\n",
    "            return self.cursor.fetchall()\n",
    "        else:\n",
    "            return self.cursor\n",
    "    \n",
    "    def _close(self):\n",
    "        if self.db:\n",
    "            self.db.close()\n",
    "            print('Closed!')\n",
    "    \n",
    "    def _show_tables(self):\n",
    "        return [table[0] for table in self._execute(query = 'SHOW TABLES', fetch = True)]\n",
    "    \n",
    "    def _has_table(self, table_name):\n",
    "        table_names = self._show_tables()\n",
    "        if table_name in table_names:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _column_names(self, table_name):\n",
    "        return [col[0] for col in self.describe(table_name)]\n",
    "    \n",
    "    def _insert(self, table_name, data: list):\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        column_names = self._column_names\n",
    "        \n",
    "        # assuming all data rows have the same columns\n",
    "        for col in data[0].keys():\n",
    "            if col not in column_names:\n",
    "                return f'Error! \"{col}\" column not found'\n",
    "        \n",
    "        column_names = list(data[0].keys())\n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(column_names)}) VALUES ({\"%s, \" * (len(column_names) - 1)}%s)'\n",
    "        values = []\n",
    "        for row in data:\n",
    "            values.append(tuple(row[col] for col in column_names))\n",
    "        try:\n",
    "            self._execute(query, values, many = True)\n",
    "            return self.db.commit()\n",
    "        except Exception as e:\n",
    "            print(f'error here: {e}')\n",
    "            self._close()\n",
    "    \n",
    "    def describe(self, table_name: str = ''):\n",
    "        if table_name:\n",
    "            query = f'DESCRIBE {table_name}'\n",
    "            return self._execute(query = query, fetch = True)\n",
    "        server_response = self._show_tables()\n",
    "        for table in server_response:\n",
    "            self.tables.append({table: self.describe(table)})\n",
    "        return self.tables\n",
    "    \n",
    "    def _read(self, table_name: str, search: dict, result_columns: bool = False):\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        query = (f'SELECT * FROM {table_name} WHERE ' \n",
    "            + ' AND '.join([f'{k} {v[\"operator\"]} {v[\"value\"]}' for k, v in search.items()]))\n",
    "        \n",
    "        server_response = self._execute(query = query, fetch = True)\n",
    "        if result_columns:\n",
    "            result = []\n",
    "            column_names = self._column_names(table_name)\n",
    "            for row in server_response:\n",
    "                result.append({name: value for name, value in zip(column_names, row)})\n",
    "            return result\n",
    "        return server_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Database(config = client, db_name = 'scopus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(339,\n",
       "  13,\n",
       "  'bye',\n",
       "  'byee',\n",
       "  'byeee',\n",
       "  datetime.datetime(2019, 6, 3, 18, 52, 47),\n",
       "  datetime.datetime(2019, 6, 3, 18, 52, 47)),\n",
       " (342,\n",
       "  14,\n",
       "  'bye',\n",
       "  'byee',\n",
       "  'byeee',\n",
       "  datetime.datetime(2019, 6, 3, 19, 5, 57),\n",
       "  datetime.datetime(2019, 6, 3, 19, 5, 57)),\n",
       " (344,\n",
       "  15,\n",
       "  'bye',\n",
       "  'byee',\n",
       "  'byeee',\n",
       "  datetime.datetime(2019, 6, 3, 19, 12),\n",
       "  datetime.datetime(2019, 6, 3, 19, 12))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.insert_first('subject', [{'asjc_code': 12, 'top': 'hi', 'middle': 'hii', 'low': 'hiii'},{'asjc_code': 15, 'top': 'bye', 'middle': 'byee', 'low': 'byeee'}])\n",
    "d._read('subject', {'asjc_code': {'value': '12', 'operator': '>'}}, result_columns=False)\n",
    "# print(d.describe('subject'))\n",
    "# d._close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asjc_code = 14'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'asjc_code': {'value': 14, 'operator': '='}, 'top': {'value': 'bye', 'operator': '<='}}\n",
    "b = ' AND '.join([f'{k} {v[\"operator\"]} {v[\"value\"]}' for k, v in a.items()])\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
