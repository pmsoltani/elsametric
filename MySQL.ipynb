{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mysql\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "with open('config.json', 'r') as read_file:\n",
    "    client = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "\n",
    "with io.open(os.path.join(path, files[0]), 'r', encoding='utf8') as raw:\n",
    "    data = json.load(raw)\n",
    "\n",
    "faculties = []\n",
    "with io.open('data\\\\faculties.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        if row['Scopus']:\n",
    "            row['Scopus'] = list(map(int, row['Scopus'].split(',')))\n",
    "        faculties.append(row)\n",
    "\n",
    "asjc = []\n",
    "with io.open('data\\\\ASJC Codes.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    for row in reader:\n",
    "        asjc.append(row)\n",
    "\n",
    "sources = []\n",
    "with io.open('data\\\\Scopus Sources.csv', 'r', encoding='utf-8-sig') as csvFile:\n",
    "    reader = csv.DictReader(csvFile)\n",
    "    to_be_removed = [\n",
    "        'Active', 'Discontinued', 'Coverage', '2016 CiteScore', '2017 CiteScore', '2018 CiteScore', \n",
    "        'Medline-sourced', 'Open Access', 'Articles in Press Included', 'Added to list April 2019', \n",
    "        'Title history indication', 'Related title to title history indication', 'Other related title 1',\n",
    "        'Other related title 2', 'Other related title 3', 'Publisher imprints grouped to main Publisher',\n",
    "    ]\n",
    "    for row in reader:\n",
    "        for col in to_be_removed:\n",
    "            row.pop(col, None)\n",
    "        row['ASJC'] = [int(code) for code in row['ASJC'].split(';') if code != '']\n",
    "        sources.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \n",
    "    table_ids = {\n",
    "        'source': {'order': 0, 'id': ['source_id_scp']},\n",
    "        'subject': {'order': 0, 'id': ['asjc_code']},\n",
    "        'country': {'order': 0, 'id': ['name']},\n",
    "        'paper_funding': {'order': 0, 'id': ['agency_id_scp']},\n",
    "        \n",
    "        'source_subject': {'order': 1, 'id': ['source_id', 'subject_id']},\n",
    "        'paper': {'order': 1, 'id': ['paper_id_scp']},\n",
    "        \n",
    "        'author': {'order': 2, 'id': ['author_id_scp']},\n",
    "        'keyword': {'order': 2, 'id': ['keyword_id']},\n",
    "        \n",
    "        'paper_author': {'order': 3, 'id': ['paper_id', 'author_id']},\n",
    "        'paper_keyword': {'order': 3, 'id': ['paper_id', 'keyword_id']},\n",
    "        'author_profile': {'order': 3, 'id': ['author_id']},\n",
    "        'institution': {'order': 3, 'id': ['institution_id_scp']},\n",
    "        \n",
    "        'department': {'order': 4, 'id': ['institution_id']},\n",
    "        \n",
    "        'author_department': {'order': 5, 'id': ['author_id', 'department_id', 'institution_id']},\n",
    "    }\n",
    "    \n",
    "    def __init__(self, config: dict, db_name: str, host: str = 'localhost', port: int = 3306, buffered: bool = True):\n",
    "        # print('@ __init__')\n",
    "        self._params = {\n",
    "            'host': host,\n",
    "            'buffered': buffered,\n",
    "            'user': config['MySQL User'],\n",
    "            'pass': config['MySQL Pass'],\n",
    "        }\n",
    "        self.db_name = db_name\n",
    "        self.db = None\n",
    "        self.cursor = None\n",
    "        self.tables = []\n",
    "        # print('__init__ done!')\n",
    "    \n",
    "    def _connect(self):\n",
    "        # print('@ _connect')\n",
    "        if not self.db:\n",
    "            self.db = mysql.connect(\n",
    "                host = self._params['host'],\n",
    "                buffered = self._params['buffered'],\n",
    "                user = self._params['user'],\n",
    "                password = self._params['pass'],\n",
    "                database = self.db_name\n",
    "            )\n",
    "        # print('_connect done!')\n",
    "        return self.db\n",
    "    \n",
    "    def _cursor(self):\n",
    "        # print('@ _cursor')\n",
    "        if not self.db:\n",
    "            self._connect()\n",
    "        if not self.db.is_connected():\n",
    "            self.db.reconnect()\n",
    "        if not self.cursor:\n",
    "            self.cursor = self.db.cursor()\n",
    "        # print('_cursor done!')\n",
    "        return self.cursor\n",
    "    \n",
    "    def _execute(self, query, values = [], fetch: bool = False, many: bool = False, close_cursor: bool = False):\n",
    "        # print('@ _execute')\n",
    "        if many:\n",
    "            self._cursor().executemany(query, values)\n",
    "        else:\n",
    "            self._cursor().execute(query, values)\n",
    "        if fetch:\n",
    "            server_response = self.cursor.fetchall()\n",
    "        else:\n",
    "            server_response = self.cursor\n",
    "        # print('_execute done!')\n",
    "        if close_cursor:\n",
    "            self.cursor.close()\n",
    "            self.cursor = None\n",
    "        return server_response\n",
    "    \n",
    "    def _close(self):\n",
    "        # print('@ _close')\n",
    "        if self.db.is_connected():\n",
    "            self.db.close()\n",
    "        # print('Closed!')\n",
    "    \n",
    "    def _show_tables(self):\n",
    "        # print('@ _show_tables')\n",
    "        return [table[0] for table in self._execute(query = 'SHOW TABLES', fetch = True)]\n",
    "    \n",
    "    def _has_table(self, table_name):\n",
    "        # print('@ _has_table')\n",
    "        table_names = self._show_tables()\n",
    "        if table_name in table_names:\n",
    "            # print('_has_table done!')\n",
    "            return True\n",
    "        # print('_has_table done!')\n",
    "        return False\n",
    "    \n",
    "    def _column_names(self, table_name):\n",
    "        # print('@ _column_names')\n",
    "        return [col[0] for col in self.describe(table_name)]\n",
    "    \n",
    "    def describe(self, table_name: str = ''):\n",
    "        # print('@ describe')\n",
    "        if table_name:\n",
    "            query = f'DESCRIBE {table_name}'\n",
    "            # print('describe done!')\n",
    "            return self._execute(query = query, fetch = True)\n",
    "        server_response = self._show_tables()\n",
    "        for table in server_response:\n",
    "            self.tables.append({table: self.describe(table)})\n",
    "        # print('describe done!')\n",
    "        return self.tables\n",
    "    \n",
    "    def _read(self, table_name: str, search: dict, select = '*', result_columns: bool = False):\n",
    "        # print('@ _read')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        if search:\n",
    "            temp_list = []\n",
    "            query = f\"SELECT {select} FROM {table_name} WHERE \"\n",
    "            for k, v in search.items():\n",
    "                if type(v[\"value\"]) != int:\n",
    "                    temp_list.append(f\"{k} {v['operator']} '{v['value']}'\")\n",
    "                else:\n",
    "                    temp_list.append(f\"{k} {v['operator']} {v['value']}\")\n",
    "            query += \" AND \".join(temp_list)\n",
    "        else:\n",
    "            query = f'SELECT {select} FROM {table_name}'\n",
    "        # print(f'query: {query}')\n",
    "        server_response = self._execute(query = query, fetch = True, close_cursor = True)\n",
    "        # print('got the response from _execute')\n",
    "        if result_columns:\n",
    "            result = []\n",
    "            if select == '*':\n",
    "                column_names = self._column_names(table_name)\n",
    "            else:\n",
    "                column_names = [column.strip() for column in select.split(',')]\n",
    "            for row in server_response:\n",
    "                result.append({name: value for name, value in zip(column_names, row)})\n",
    "            # print('_read done!')\n",
    "            return result\n",
    "        # print('_read done!')\n",
    "        return server_response\n",
    "    \n",
    "    # def has_row(self, table_name, row_ids: dict):\n",
    "    #     # print('@ has_row')\n",
    "    #     search = {}\n",
    "    #     for row_id in row_ids:\n",
    "    #         search[row_id] = {'value': row_ids[row_id], 'operator': '='}\n",
    "    #     server_response = self._read(table_name, search, select = 'COUNT(*)')\n",
    "    #     # print('has_row done!')\n",
    "    #     return server_response[0][0]\n",
    "    \n",
    "    def _insert_one(self, table_name, data: dict):\n",
    "        # data is a list of dictionaries\n",
    "        # print('@ _insert_one')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        table_columns = self._column_names(table_name)\n",
    "        data_columns = list(data.keys())\n",
    "        for col in data_columns:\n",
    "            if col not in table_columns:\n",
    "                return f'Error! \"{col}\" column not found'\n",
    "        \n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(data_columns)}) VALUES ({\"%s, \" * (len(data_columns) - 1)}%s)'\n",
    "        \n",
    "        # check if the record already exists\n",
    "        id_columns = Database.table_ids[table_name]['id']\n",
    "        # print(f'id_columns: {id_columns}')\n",
    "        search = {id_column: {'value': data[id_column], 'operator': '='} for id_column in id_columns}\n",
    "        # print(f'search: {search}')\n",
    "        server_response = self._read(table_name, search)\n",
    "        if server_response: # record exists, let's return the its primary key\n",
    "            server_response = server_response[-1][0]\n",
    "            return {'msg': f'Table \"{table_name}\" already has this record', 'value': server_response}\n",
    "        \n",
    "        # record is new\n",
    "        values = tuple(data[col] for col in data_columns)\n",
    "        try:\n",
    "            self._execute(query, values)\n",
    "            # print('_insert_one done!')\n",
    "            self.db.commit()\n",
    "            last_id = self.cursor.lastrowid\n",
    "            self._close()\n",
    "            return {'msg': f'Record added to \"{table_name}\"', 'value': last_id}\n",
    "        except Exception as e:\n",
    "            return f'error here: {e}'\n",
    "            self._close()\n",
    "        \n",
    "    def _insert_many(self, table_name, data: list):\n",
    "        # data is a list of dictionaries\n",
    "        # print('@ _insert')\n",
    "        if not self._has_table(table_name):\n",
    "            return f'Error! \"{table_name}\" table not found'\n",
    "        \n",
    "        # assuming all data rows have the same columns\n",
    "        # data is a list of dictionaries, of which the keys are column names\n",
    "        table_columns = self._column_names(table_name)\n",
    "        data_columns = list(data[0].keys())\n",
    "        for col in data_columns:\n",
    "            if col not in table_columns:\n",
    "                return f'Error! \"{col}\" column not found'\n",
    "        \n",
    "        query = f'INSERT INTO {table_name} ({\", \".join(data_columns)}) VALUES ({\"%s, \" * (len(data_columns) - 1)}%s)'\n",
    "        values = []\n",
    "        id_columns = Database.table_ids[table_name]['id']\n",
    "        skipped_rows = 0\n",
    "        total_rows = len(data)\n",
    "        for row in data:\n",
    "            search = {id_column: {'value': row[id_column], 'operator': '='} for id_column in id_columns}\n",
    "            if self._read(table_name, search):\n",
    "                skipped_rows += 1\n",
    "                continue\n",
    "            values.append(tuple(row[col] for col in data_columns))\n",
    "        try:\n",
    "            self._execute(query, values, many = True)\n",
    "            # print('_insert done!')\n",
    "            self.db.commit()\n",
    "            last_id = self.cursor.lastrowid\n",
    "            self._close()\n",
    "            return {'msg': f'{total_rows - skipped_rows} records added ({skipped_rows} already existed)', 'value': last_id}\n",
    "        except Exception as e:\n",
    "            # print(f'error here: {e}')\n",
    "            self._close()\n",
    "    \n",
    "    def raw_insert(self, data: list, retrieval_time):\n",
    "        # print('@ raw_insert')\n",
    "        # data is a dictionary containing the info about 1 paper\n",
    "        warnings = data_inspector(data)\n",
    "        if 'openaccess' in warnings:\n",
    "            data['openaccess'] = '0'\n",
    "            warnings.pop('openaccess')\n",
    "        if 'author:afid' in warnings:\n",
    "            warnings.pop('author:afid')\n",
    "        if len(warnings):\n",
    "            self._close()\n",
    "            return {'warnings': warnings, 'value': None}\n",
    "        \n",
    "        keys = data.keys()\n",
    "        \n",
    "        paper_url = ''\n",
    "        for link in data['link']:\n",
    "            if link['@ref'] == 'scopus':\n",
    "                paper_url = link['@href']\n",
    "                break\n",
    "\n",
    "        paper_id_scp = int(data['dc:identifier'].split(':')[1])\n",
    "        search = {'paper_id_scp': {'value': paper_id_scp, 'operator': '='}}\n",
    "        if self._read('paper', search):\n",
    "            self._close()\n",
    "            return {'warnings': ['paper exists'], 'value': self._read('paper', search)[-1][0]}\n",
    "        \n",
    "        source_id_scp = int(data['source-id'])\n",
    "        agency_id_scp = key_get(data, keys, 'fund-no')\n",
    "        if agency_id_scp == 'undefined':\n",
    "            agency_id_scp = None\n",
    "        \n",
    "        source_info = {\n",
    "            'source_id_scp': source_id_scp, \n",
    "            'title': data['prism:publicationName'], \n",
    "            'url': f'https://www.scopus.com/sourceid/{source_id_scp}', \n",
    "            'type': key_get(data, keys, 'prism:aggregationType'), \n",
    "            'issn': key_get(data, keys, 'prism:issn'), \n",
    "            'e_issn': key_get(data, keys, 'prism:eIssn'), \n",
    "            'isbn': key_get(data, keys, 'prism:isbn'), \n",
    "            'publisher': None, \n",
    "            'country_id': None\n",
    "        }\n",
    "        \n",
    "        source_id = self._insert_one('source', source_info)['value']\n",
    "        \n",
    "        agency_id = None\n",
    "        if agency_id_scp:\n",
    "            paper_funding_info = {\n",
    "                'agency_id_scp': agency_id_scp, \n",
    "                'agency': key_get(data, keys, 'fund-sponsor'), \n",
    "                'agency_acronym': key_get(data, keys, 'fund-acr'), \n",
    "            }\n",
    "            # print(paper_funding_info)\n",
    "            agency_id = self._insert_one('paper_funding', paper_funding_info)['value']            \n",
    "            \n",
    "        paper_info = {\n",
    "            'paper_id_scp': paper_id_scp,\n",
    "            'eid': data['eid'],\n",
    "            'title': data['dc:title'],\n",
    "            'type': data['subtype'],\n",
    "            'type_description': key_get(data, keys, 'subtypeDescription'),\n",
    "            'abstract': key_get(data, keys, 'dc:description'),\n",
    "            'total_author': key_get(data, keys, 'author-count'),\n",
    "            'open_access': data['openaccess'],\n",
    "            'cited_cnt': data['citedby-count'],\n",
    "            'url': paper_url,\n",
    "            'article_no': key_get(data, keys, 'prism:volume'),\n",
    "            'agency_id': agency_id,\n",
    "            'retrieval_time': retrieval_time,\n",
    "            'source_id': source_id,\n",
    "            'doi': key_get(data, keys, 'prism:doi'),\n",
    "            'volume': key_get(data, keys, 'prism:volume'),\n",
    "            'issue': key_get(data, keys, 'prism:issueIdentifier'),\n",
    "            'page_range': key_get(data, keys, 'prism:pageRange'),\n",
    "            'date': data['prism:coverDate'],\n",
    "        }\n",
    "        \n",
    "        if 256 < len(paper_info['title']):\n",
    "            return {'warnings': [f'title too long ({len(paper_info[\"title\"])} chars)'], 'value': None}\n",
    "        paper_id = self._insert_one('paper', paper_info)['value']\n",
    "        \n",
    "        author_institution = []\n",
    "        paper_author_info = []\n",
    "        for author in data['author']:\n",
    "            keys = author.keys()\n",
    "            author_id_scp = int(author['authid'])\n",
    "            author_info = {\n",
    "                'author_id_scp': author_id_scp,\n",
    "                'first': key_get(author, keys, 'given-name'),\n",
    "                'last': key_get(author, keys, 'surname'),\n",
    "                'initials': key_get(author, keys, 'initials'),\n",
    "            }\n",
    "            author_id = self._insert_one('author', author_info)['value']\n",
    "            \n",
    "            paper_author_info = {\n",
    "                'paper_id': paper_id,\n",
    "                'author_id': author_id,\n",
    "                'author_no': int(author['@seq']),\n",
    "            }\n",
    "            self._insert_one('paper_author', paper_author_info)\n",
    "            \n",
    "            author_profile_info = {\n",
    "                'author_id': author_id,\n",
    "                'address': f'https://www.scopus.com/authid/detail.uri?authorId={author_id_scp}',\n",
    "                'type': 'Scopus Profile',\n",
    "            }\n",
    "            profile_id = self._insert_one('author_profile', author_profile_info)['value']\n",
    "            \n",
    "            institution_id_scp = key_get(author, keys, 'afid', many=True)\n",
    "            author_institution.append([author_id, institution_id_scp])\n",
    "        \n",
    "        for institution in data['affiliation']:\n",
    "            keys = institution.keys()\n",
    "            institution_id_scp = int(institution['afid'])\n",
    "            institution_info = {\n",
    "                'institution_id_scp': institution_id_scp,\n",
    "                'name': institution['affilname'],\n",
    "                'city': key_get(institution, keys, 'affiliation-city'),\n",
    "                'url': f'https://www.scopus.com/affil/profile.uri?afid={institution_id_scp}',\n",
    "                # 'country': key_get(institution, keys, 'affiliation-city'),\n",
    "            }\n",
    "            institution_id = self._insert_one('institution', institution_info)['value']\n",
    "            \n",
    "            department_info = {\n",
    "                'institution_id': institution_id,\n",
    "                'name': 'Department Not Available',\n",
    "                'abbreviation': 'No Dept',\n",
    "            }\n",
    "            department_id = self._insert_one('department', department_info)['value']\n",
    "            \n",
    "            for item in author_institution:\n",
    "                if item[1]: # author's \"afid\" is known\n",
    "                    if institution_id_scp in item[1]:\n",
    "                        author_department_info = {\n",
    "                            'author_id': item[0],\n",
    "                            'department_id': department_id,\n",
    "                            'institution_id': institution_id,\n",
    "                        }\n",
    "                        self._insert_one('author_department', author_department_info)\n",
    "        # print('raw_insert done')\n",
    "        return {'msg': 'Scopus paper inserted', 'value': paper_id}\n",
    "\n",
    "# table_ids = {\n",
    "#         'subject': {'order': 0, 'id': ['asjc_code']},\n",
    "#         'country': {'order': 0, 'id': ['name']},\n",
    "\n",
    "#         'source_subject': {'order': 1, 'id': ['source_id', 'subject_id']},\n",
    "\n",
    "#         'keyword': {'order': 2, 'id': ['keyword_id']},\n",
    "        \n",
    "#         'paper_keyword': {'order': 3, 'id': ['paper_id', 'keyword_id']},\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_inspector(data: dict):\n",
    "    warnings = []\n",
    "    top_keys = [\n",
    "        'source-id', 'prism:publicationName', 'prism:coverDate',\n",
    "        'dc:identifier', 'eid', 'dc:title', 'subtype', 'author-count', 'openaccess', 'citedby-count', 'link', \n",
    "        'author', 'affiliation',\n",
    "    ]\n",
    "    author_keys = ['authid', '@seq', 'afid']\n",
    "    affiliation_keys = ['afid', 'affilname']\n",
    "    \n",
    "    keys = data.keys()\n",
    "    for key in top_keys:\n",
    "        if key not in keys:\n",
    "            warnings.append(key)\n",
    "    if 'link' not in warnings:\n",
    "        if all(link['@ref'] != 'scopus' for link in data['link']):\n",
    "            warnings.append('paper url')\n",
    "    if 'author' not in warnings:\n",
    "        for author in data['author']:\n",
    "            keys = author.keys()\n",
    "            for key in author_keys:\n",
    "                if key not in keys:\n",
    "                    warnings.append(f'author:{key}')\n",
    "    if 'affiliation' not in warnings:\n",
    "        for affiliation in data['affiliation']:\n",
    "            keys = affiliation.keys()\n",
    "            for key in affiliation_keys:\n",
    "                if key not in keys:\n",
    "                    warnings.append(f'affiliation:{key}')\n",
    "    return warnings\n",
    "\n",
    "def key_get(data: dict, keys, key: str, many: bool = False):\n",
    "    result = (data[key] if key in keys else None)\n",
    "    if type(result) == list:\n",
    "        if not many:\n",
    "            return result[0]['$']\n",
    "        return [int(item['$']) for item in result]\n",
    "    if type(result) == dict:\n",
    "        return result['$']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = Database(config = client, db_name = 'scopus')\n",
    "# d._insert_many('paper_funding', [{'agency_id_scp': 27, 'agency': 'FQatar', 'agency_acronym': 'QNSF'}])#,{'agency_id_scp': 13, 'agency': 'US', 'agency_acronym': 'NSF'}])\n",
    "# d._insert_many('source_subject', [{'source_id': 2, 'subject_id': 2},{'subject_id': 3, 'source_id': 1}])\n",
    "# d._read('paper_funding', {'agency_id_scp': {'value': 2, 'operator': '='}}, result_columns=True)\n",
    "# d._insert_one('paper_funding', {'agency_id_scp': 2, 'agency': 'FQatar', 'agency_acronym': 'QNSF'})#,{'agency_id_scp': 13, 'agency': 'US', 'agency_acronym': 'NSF'}])\n",
    "# d._read('source_subject', {'source_id': {'value': 1, 'operator': '='}, 'subject_id': {'value': 3, 'operator': '='}}, result_columns=True)\n",
    "# d._table_order()\n",
    "# print(d.describe('subject'))\n",
    "# d._close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharif University of Technology_y2018_005_S9J79E_1558880320.txt\n",
      "SCOPUS_ID:85057278003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'warnings': ['title too long (260 chars)'], 'value': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "start = time.time()\n",
    "paper_cnt = 0\n",
    "skipped_cnt = 0\n",
    "db = Database(config = client, db_name = 'scopus')\n",
    "path = 'data\\\\Sharif University of Technology'\n",
    "files = list(os.walk(path))[0][2]\n",
    "for file in files[5:]:\n",
    "    with io.open(os.path.join(path, file), 'r', encoding='utf8') as raw:\n",
    "        data = json.load(raw)\n",
    "    data = data['search-results']['entry']\n",
    "    ret_time = datetime.utcfromtimestamp(int(file.split('.')[0].split('_')[-1])).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    for paper in data:\n",
    "        warnings = data_inspector(paper)\n",
    "        print(file)\n",
    "        print(paper['dc:identifier'])\n",
    "        ins_id = db.raw_insert(paper, retrieval_time=ret_time)\n",
    "        print(ins_id)\n",
    "        paper_cnt += 1\n",
    "        if 'msg' not in ins_id.keys():\n",
    "            skipped_cnt += 1\n",
    "        print('---------------------')\n",
    "end = time.time()\n",
    "db._close()\n",
    "print()\n",
    "print()\n",
    "print(f'Transaction time: {end - start} seconds')\n",
    "print(f'{len(files)} file reviewed')\n",
    "print(f'{paper_cnt} papers reviewed')\n",
    "print(f'{skipped_cnt} papers skipped')\n",
    "print(f'{paper_cnt - skipped_cnt} papers inserted into the db')\n",
    "# ins_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
